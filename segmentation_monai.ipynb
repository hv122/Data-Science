{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification vs Detection vs Segmentation\n",
    "\n",
    "* Classification is just determining whether an object exists or not in an image\n",
    "* Detection is determining where the object is in the image, and drawing a bounding box around it\n",
    "* Segmentation is determining where the object is in the image, and drawing a mask around it, i.e. a pixel-wise classification\n",
    "\n",
    "\n",
    "Segmentation is also divided into two types: semantic and instance segmentation. Semantic segmentation is when you classify each pixel into a class, e.g. \"car\", \"person\", \"road\", etc. Instance segmentation is when you classify each pixel into a class, but also assign each instance of the class a unique ID, e.g. \"car1\", \"car2\", \"person1\", \"person2\", etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Architecture\n",
    "\n",
    "We use the U-Net Architecture, which is made up of convolution, max pooling and ReLU layers. U-Nets output predicted channels for what we are searching for, predicted channels for the background, and an input mask. These are collated to form a binary image to highlight the specific part of the image we want."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
