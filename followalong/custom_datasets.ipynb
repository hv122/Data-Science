{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a custom dataset?\n",
    "\n",
    "Custom datasets are datasets not created specifically for use as input data for Neural Networks, so we need to adjust said data before we are able to use it to train and test our models.\n",
    "\n",
    "We use different PyTorch domain libraries dependent on our problem space, these can include:\n",
    "\n",
    "- Vision - `torchvision`\n",
    "- Text - `torchtext`\n",
    "- Audio - `torchaudio`\n",
    "- Recommendation Systems - `torchrec`\n",
    "\n",
    "TorchData is also a new domain we can use for all sort of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FoodVisionMini\n",
    "\n",
    "This will be a CNN that takes in custom data, following our PyTorch workflow as seen below.\n",
    "\n",
    "- Get data ready (turn into tensors)\n",
    "- Pick a loss function and optimizer\n",
    "- Build or pick a pretrained model to suit our problem\n",
    "- Fit the model to the data and make a prediction\n",
    "- Evaluate the model\n",
    "- Improve the model through experimentation\n",
    "- Save and reload the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Setup device-agnostic code\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Data\n",
    "\n",
    "Food101 starts with 101 different classes of food and 1000 images per class.\n",
    "\n",
    "Our dataset, a subset of Food101, starts with just 3 classes, and 100 images per class.\n",
    "\n",
    "When starting out ML projects, it's important to try things on a small scale and then increase the scale when necessary. The use is to speed up how fast you can experiment. If we don't do this, we will take ages to train every model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/pizza_steak_sushi directory already exists... skipping download\n",
      "Downloading data...\n",
      "Unzipping data\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Setup path to a data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory already exists... skipping download\")\n",
    "else:\n",
    "    print(f\"{image_path} does not exist, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download data to pizza_steak_sushi\n",
    "\n",
    "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "    print(\"Downloading data...\")\n",
    "    f.write(request.content)\n",
    "\n",
    "# Unzip file\n",
    "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "    print(\"Unzipping data\")\n",
    "    zip_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing and exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 images in 'data/pizza_steak_sushi'.\n",
      "There are 3 directories and 0 images in 'data/pizza_steak_sushi/test'.\n",
      "There are 0 directories and 19 images in 'data/pizza_steak_sushi/test/steak'.\n",
      "There are 0 directories and 31 images in 'data/pizza_steak_sushi/test/sushi'.\n",
      "There are 0 directories and 25 images in 'data/pizza_steak_sushi/test/pizza'.\n",
      "There are 3 directories and 0 images in 'data/pizza_steak_sushi/train'.\n",
      "There are 0 directories and 75 images in 'data/pizza_steak_sushi/train/steak'.\n",
      "There are 0 directories and 72 images in 'data/pizza_steak_sushi/train/sushi'.\n",
      "There are 0 directories and 78 images in 'data/pizza_steak_sushi/train/pizza'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def walk_through_dir(dir_path):\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
    "\n",
    "walk_through_dir(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup train and test paths\n",
    "\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "# We can use this as an alternative to the train test split we did earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualising and image "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
